# helm-charts/order-service/values.yaml
replicaCount: 1

image:
  repository: 614520203046.dkr.ecr.us-east-1.amazonaws.com/order-service
  tag: "1.0.0-e3a80fd"
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: "order-service"

service:
  name: order-service
  type: ClusterIP
  port: 3000
  targetPort: 3000

# Argo Rollouts Strategy
strategy:
  type: canary
  canary:
    steps:
      - setWeight: 20
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: order-service-analysis
      - setWeight: 40
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: order-service-analysis
      - setWeight: 60
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: order-service-analysis
      - setWeight: 80
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: order-service-analysis
      - setWeight: 100
    trafficRouting:
      istio:
        virtualService:
          name: order-service
          routes:
            - primary
    analysisInterval: 1m
    analysisSuccessCount: 5
    analysisFailureLimit: 3

# Istio Configuration
istio:
  enabled: true
  gateway:
    enabled: false
  virtualService:
    enabled: true
    hosts:
      - order-service
  destinationRule:
    enabled: true

# HPA Configuration - Fast Scaling (1-6 replicas)
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 6
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 60    # Wait 1 minute before scaling down
      policies:
        - type: Percent
          value: 100                     # Can scale down 100% per period
          periodSeconds: 15              # Check every 15 seconds
        - type: Pods
          value: 2                       # Can remove up to 2 pods at once
          periodSeconds: 15
      selectPolicy: Max                  # Use the policy that scales down faster
    scaleUp:
      stabilizationWindowSeconds: 0      # Scale up immediately
      policies:
        - type: Percent
          value: 100                     # Double pods per period
          periodSeconds: 15              # Check every 15 seconds
        - type: Pods
          value: 3                       # Can add up to 3 pods at once
          periodSeconds: 15
      selectPolicy: Max  

# Resource limits
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 200m
    memory: 256Mi

# Probes
probes:
  startup:
    httpGet:
      path: /health
      port: 3000
    initialDelaySeconds: 20
    failureThreshold: 5
    periodSeconds: 10
  readiness:
    httpGet:
      path: /health
      port: 3000
    initialDelaySeconds: 3
    failureThreshold: 3
    periodSeconds: 5
  liveness:
    httpGet:
      path: /health
      port: 3000
    initialDelaySeconds: 3
    failureThreshold: 5
    periodSeconds: 3

# Environment variables
env:
  - name: ORDER_QUEUE_HOSTNAME
    value: "rabbitmq.default.svc.cluster.local"
  - name: ORDER_QUEUE_PORT
    value: "5672"
  - name: ORDER_QUEUE_NAME
    value: "orders"
  - name: FASTIFY_ADDRESS
    value: "0.0.0.0"

# Init Container for RabbitMQ readiness
initContainers:
  - name: wait-for-rabbitmq
    image: busybox:1.36
    command: 
      - 'sh'
      - '-c'
      - 'until nc -zv rabbitmq.default.svc.cluster.local 5672; do echo waiting for rabbitmq; sleep 2; done;'
    resources:
      requests:
        cpu: 1m
        memory: 50Mi
      limits:
        cpu: 100m
        memory: 256Mi

# Vault Configuration
vault:
  enabled: true
  role: "order-service"
  secrets:
    rabbitmq:
      path: "kv/data/order-service"
      # This template will be rendered by Vault, not Helm
      # The |- preserves the template syntax for Vault to process
      template: |-
        {{- with secret "kv/data/order-service" -}}
        export ORDER_QUEUE_USERNAME="{{ .Data.data.rabbitmq_username }}"
        export ORDER_QUEUE_PASSWORD="{{ .Data.data.rabbitmq_password }}"
        {{- end -}}

# Datadog Configuration
datadog:
  enabled: true
  env: production
  service: order-service
  version: "1.0.0-e3a80fd"
  logs:
    enabled: true
  apm:
    enabled: true
    language: nodejs
  profiling:
    enabled: false

# Prometheus Metrics
metrics:
  enabled: false
  serviceMonitor:
    enabled: false
    interval: 30s
    path: /metrics

# Node selector
nodeSelector:
  kubernetes.io/os: linux

tolerations: []
affinity: {}
podAnnotations: {}
podLabels: {}

# Analysis Template Configuration
analysis:
  enabled: true
  provider: datadog
  datadog:
    secretName: datadog-secret
    metrics:
      - name: error-rate
        query: "avg:trace.http.request.errors{service:order-service,env:production}.as_rate()"
        successCondition: "default(result, 0) < 0.05"
        failureLimit: 3
        interval: 1m
        count: 5
      - name: p95-latency
        query: "avg:trace.http.request.duration.by.service.95p{service:order-service,env:production}"
        successCondition: "default(result, 0) < 1000"
        failureLimit: 3
        interval: 1m
        count: 5