# helm-charts/store-front/values.yaml
replicaCount: 1

image:
  repository: 614520203046.dkr.ecr.us-east-1.amazonaws.com/store-front
  tag: "1.0.0-76fd7df"  # ⚠️ CHANGE from "latest" to specific version
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: "store-front"

service:
  name: store-front
  type: ClusterIP
  port: 80
  targetPort: 8080

# ALB Ingress Configuration - For external customer traffic
ingress:
  enabled: true  # ✅ ENABLED - Following store-admin pattern
  annotations:
    alb.ingress.kubernetes.io/tags: Environment=production,Team=platform,Service=store-front
  hosts:
    - host: "devopsproduction.com"  # ✅ Main customer-facing domain
      paths:
        - path: /
          pathType: Prefix
  tls:
    - secretName: store-front-tls
      hosts:
        - devopsproduction.com
  alb:
    scheme: internet-facing
    targetType: ip
    certificateArn: arn:aws:acm:us-east-1:614520203046:certificate/1701a5c8-591c-4f5d-a3d1-d8773c15dc31  # ✅ Same cert as store-admin

# Argo Rollouts Strategy - BLUE-GREEN
strategy:
  type: blueGreen
  blueGreen:
    activeService: store-front
    previewService: store-front-preview
    autoPromotionEnabled: true
    autoPromotionSeconds: 300
    scaleDownDelaySeconds: 300
    prePromotionAnalysis:
      templates:
        - templateName: store-front-analysis
    postPromotionAnalysis:
      templates:
        - templateName: store-front-analysis

# Istio Configuration - For service mesh & observability (same as store-admin)
istio:
  enabled: true  # ✅ ENABLED for service mesh
  gateway:
    enabled: false  # ❌ DISABLED - Using ALB for external traffic
    name: store-gateway
    hosts:
      - "*"
  virtualService:
    enabled: true  # ✅ ENABLED for internal routing & telemetry
    hosts:
      - store-front
      - store-front.frontend.svc.cluster.local
  destinationRule:
    enabled: true  # ✅ ENABLED for circuit breaking & load balancing

# HPA Configuration - Customer-facing, needs faster scaling
autoscaling:
  enabled: true
  minReplicas: 2  # ⚠️ CHANGED: Customer-facing should have min 2 replicas
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 60
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 2
          periodSeconds: 15
      selectPolicy: Max
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 1
          periodSeconds: 15
      selectPolicy: Max

# Resource limits
resources:
  requests:
    cpu: 100m
    memory: 128Mi
  limits:
    cpu: 200m
    memory: 256Mi

# Probes
probes:
  startup:
    httpGet:
      path: /health
      port: 8080
    initialDelaySeconds: 5
    failureThreshold: 3
    periodSeconds: 5
  readiness:
    httpGet:
      path: /health
      port: 8080
    initialDelaySeconds: 3
    failureThreshold: 3
    periodSeconds: 5
  liveness:
    httpGet:
      path: /health
      port: 8080
    initialDelaySeconds: 3
    failureThreshold: 5
    periodSeconds: 3

# Environment variables - ✅ CORRECTED service URLs with namespaces
env:
  - name: VUE_APP_ORDER_SERVICE_URL
    value: "http://order-service.application.svc.cluster.local:3000/"
  - name: VUE_APP_PRODUCT_SERVICE_URL
    value: "http://product-service.application.svc.cluster.local:3002/"

# Init containers - Wait for backend services
initContainers:
  - name: wait-for-order-service
    image: busybox:1.36
    command: 
      - 'sh'
      - '-c'
      - 'until nc -zv order-service.application.svc.cluster.local 3000; do echo waiting for order-service; sleep 2; done;'
    resources:
      requests:
        cpu: 1m
        memory: 50Mi
      limits:
        cpu: 100m
        memory: 256Mi
  - name: wait-for-product-service
    image: busybox:1.36
    command: 
      - 'sh'
      - '-c'
      - 'until nc -zv product-service.application.svc.cluster.local 3002; do echo waiting for product-service; sleep 2; done;'
    resources:
      requests:
        cpu: 1m
        memory: 50Mi
      limits:
        cpu: 100m
        memory: 256Mi

# Vault Configuration - DISABLED for now
vault:
  enabled: false

# Datadog Configuration
datadog:
  enabled: true
  env: production
  service: store-front
  logs:
    enabled: true
  apm:
    enabled: false  # Use RUM for frontend
  profiling:
    enabled: false

# Prometheus Metrics
metrics:
  enabled: false
  serviceMonitor:
    enabled: false

# Node selector
nodeSelector:
  kubernetes.io/os: linux

tolerations: []
affinity: {}
podAnnotations: {}
podLabels: {}

# Analysis Template Configuration - Using Datadog like store-admin
analysis:
  enabled: true
  provider: datadog
  datadog:
    secretName: datadog-secret
    metrics:
      - name: error-rate
        query: "avg:trace.http.request.errors{service:store-front,env:production}.as_rate()"
        successCondition: "default(result, 0) < 0.05"  # Less than 5% error rate
        failureLimit: 3
        interval: 1m
        count: 5
      
      - name: p95-latency
        query: "avg:trace.http.request.duration.by.service.95p{service:store-front,env:production}"
        successCondition: "default(result, 0) < 2000"  # Less than 2s latency
        failureLimit: 3
        interval: 1m
        count: 5
      
      - name: request-count
        query: "sum:trace.http.request.hits{service:store-front,env:production}.as_count()"
        successCondition: "default(result, 0) > 0"  # At least some traffic
        failureLimit: 3
        interval: 1m
        count: 5