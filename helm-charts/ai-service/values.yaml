# helm-charts/ai-service/values.yaml
# Default values for ai-service

replicaCount: 1

image:
  repository: 614520203046.dkr.ecr.us-east-1.amazonaws.com/ai-service
  tag: "1.0.0-becab97"
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  name: "ai-service"

service:
  name: ai-service
  type: ClusterIP
  port: 5001
  targetPort: 5001

# Argo Rollouts Strategy
strategy:
  type: canary  # canary, blueGreen, or rolling
  canary:
    steps:
      - setWeight: 20
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: ai-service-analysis
      - setWeight: 40
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: ai-service-analysis
      - setWeight: 60
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: ai-service-analysis
      - setWeight: 80
      - pause:
          duration: 5m
      - analysis:
          templates:
            - templateName: ai-service-analysis
      - setWeight: 100
    trafficRouting:
      istio:
        virtualService:
          name: ai-service
          routes:
            - primary
    analysisInterval: 1m
    analysisSuccessCount: 2
    analysisFailureLimit: 3

# Istio Configuration
istio:
  enabled: true
  gateway:
    enabled: false  # ai-service is internal, no external gateway
  virtualService:
    enabled: true
    hosts:
      - ai-service
  destinationRule:
    enabled: true

# HPA Configuration
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 2
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 85
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 80 
      policies:
        - type: Percent
          value: 50
          periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 30

# Resource limits
resources:
  requests:
    cpu: 200mm
    memory: 150Mi
  limits:
    cpu: 400m
    memory: 300Mi

# Probes
probes:
  startup:
    httpGet:
      path: /health
      port: 5001
    initialDelaySeconds: 60
    failureThreshold: 3
    periodSeconds: 5
  readiness:
    httpGet:
      path: /health
      port: 5001
    initialDelaySeconds: 3
    failureThreshold: 10
    periodSeconds: 10
  liveness:
    httpGet:
      path: /health
      port: 5001
    initialDelaySeconds: 3
    failureThreshold: 10
    periodSeconds: 10

# Environment variables
env:
  - name: USE_AZURE_OPENAI
    value: "False"
  - name: AZURE_OPENAI_DALLE_DEPLOYMENT_NAME
    value: "dall-e-3"
  - name: AZURE_OPENAI_DALLE_ENDPOINT
    value: "https://store-app.openai.azure.com"
  - name: AZURE_OPENAI_API_VERSION
    value: "2024-02-15-preview"
  - name: USE_AZURE_AD
    value: "False"

# Vault Configuration
vault:
  enabled: true
  role: "ai-service"
  secrets:
    openai:  # Named key instead of array
      path: "kv/data/ai-service"
      template: |
        {{- with secret "kv/data/ai-service" -}}
        export OPENAI_API_KEY={{ printf "%q" .Data.data.openai_api_key }}
        export OPENAI_ORG_ID={{ printf "%q" .Data.data.openai_org_id }}
        export AZURE_OPENAI_API_KEY={{ printf "%q" .Data.data.azure_openai_api_key }}
        {{ end }}

# Datadog Configuration
datadog:
  enabled: true
  env: production
  service: ai-service
  # version: "{{ .Values.image.tag }}"
  logs:
    enabled: true
  apm:
    enabled: true
    language: python  # python, nodejs, golang, java, etc.
  profiling:
    enabled: false

# Prometheus Metrics (Optional - for future use)
metrics:
  enabled: false  # Set to true if you add /metrics endpoint
  serviceMonitor:
    enabled: false
    interval: 30s
    path: /metrics

# Node selector
nodeSelector:
  kubernetes.io/os: linux

# Tolerations
tolerations: []

# Affinity
affinity: {}

# Pod annotations
podAnnotations: {}

# Pod labels
podLabels: {}

# Analysis Template Configuration
analysis:
  enabled: true
  provider: datadog
  datadog:
    secretName: datadog-secret  # Simplified - just the secret name
    metrics:
      - name: error-rate
        query: "avg:trace.http.request.errors{service:ai-service,env:production}.as_rate()"
        successCondition: "default(result, 0) < 0.05"  # Added default() for nil handling
        failureLimit: 3
        interval: 1m
        count: 5
      - name: p95-latency
        query: "avg:trace.http.request.duration.by.service.95p{service:ai-service,env:production}"
        successCondition: "default(result, 0) < 1000"  # Added default() for nil handling
        failureLimit: 3
        interval: 1m
        count: 5